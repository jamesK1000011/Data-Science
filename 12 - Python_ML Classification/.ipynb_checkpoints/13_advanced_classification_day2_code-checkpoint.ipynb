{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## 13 ADVANCED CLASSIFICATION DAY2 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 2: Directory settings  ####\n",
    "\n",
    "# Set `main_dir` to the location of your `af-werx` folder (for Linux).\n",
    "#main_dir = \"/home/Datascience/Desktop/af-werx\"\n",
    "# Set `main_dir` to the location of your `af-werx` folder (for Mac).\n",
    "main_dir = '/Users/datasociety/Desktop/af-werx'\n",
    "# Set `main_dir` to the location of your `af-werx` folder (for Windows).\n",
    "#main_dir = \"C:\\\\Users\\\\[username]\\\\Desktop\\\\af-werx\"\n",
    "# Make `data_dir` from the `main_dir` and\n",
    "# remainder of the path to data directory.\n",
    "data_dir = main_dir + \"/data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 3: Loading packages  ####\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "# New today\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/datasociety/Desktop/af-werx/data\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 4: Working directory  ####\n",
    "\n",
    "# Set working directory.\n",
    "os.chdir(data_dir)\n",
    "# Check working directory.\n",
    "print(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rooms</th>\n",
       "      <th>tablet</th>\n",
       "      <th>males_under_12</th>\n",
       "      <th>males_over_12</th>\n",
       "      <th>females_under_12</th>\n",
       "      <th>females_over_12</th>\n",
       "      <th>years_of_schooling</th>\n",
       "      <th>wall_block_brick</th>\n",
       "      <th>wall_socket</th>\n",
       "      <th>wall_prefab_cement</th>\n",
       "      <th>...</th>\n",
       "      <th>num_mobilephones</th>\n",
       "      <th>region_central</th>\n",
       "      <th>region_Chorotega</th>\n",
       "      <th>region_pacifico</th>\n",
       "      <th>region_brunca</th>\n",
       "      <th>region_antlantica</th>\n",
       "      <th>region_huetar</th>\n",
       "      <th>urban_zone</th>\n",
       "      <th>age</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rooms  tablet  males_under_12  males_over_12  females_under_12  \\\n",
       "0      3       0               0              1                 0   \n",
       "1      4       1               0              1                 0   \n",
       "2      8       0               0              0                 0   \n",
       "3      5       1               0              2                 1   \n",
       "4      5       1               0              2                 1   \n",
       "\n",
       "   females_over_12  years_of_schooling  wall_block_brick  wall_socket  \\\n",
       "0                0                  10                 1            0   \n",
       "1                0                  12                 0            0   \n",
       "2                1                  11                 0            0   \n",
       "3                1                   9                 1            0   \n",
       "4                1                  11                 1            0   \n",
       "\n",
       "   wall_prefab_cement   ...    num_mobilephones  region_central  \\\n",
       "0                   0   ...                   1               1   \n",
       "1                   0   ...                   1               1   \n",
       "2                   0   ...                   0               1   \n",
       "3                   0   ...                   3               1   \n",
       "4                   0   ...                   3               1   \n",
       "\n",
       "   region_Chorotega  region_pacifico  region_brunca  region_antlantica  \\\n",
       "0                 0                0              0                  0   \n",
       "1                 0                0              0                  0   \n",
       "2                 0                0              0                  0   \n",
       "3                 0                0              0                  0   \n",
       "4                 0                0              0                  0   \n",
       "\n",
       "   region_huetar  urban_zone  age  Target  \n",
       "0              0           1   43    True  \n",
       "1              0           1   67    True  \n",
       "2              0           1   92    True  \n",
       "3              0           1   17    True  \n",
       "4              0           1   37    True  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 10: Load the cleaned dataset  ####\n",
    "\n",
    "os.chdir(data_dir)\n",
    "costa_clean = pickle.load(open(\"costa_no_hc.sav\",\"rb\"))\n",
    "costa_clean.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rooms', 'tablet', 'males_under_12', 'males_over_12',\n",
       "       'females_under_12', 'females_over_12', 'years_of_schooling',\n",
       "       'wall_block_brick', 'wall_socket', 'wall_prefab_cement', 'wall_wood',\n",
       "       'floor_mos_cer_terr', 'floor_wood', 'ceiling', 'electric_public',\n",
       "       'toilet_sewer', 'cookenergy_elec', 'trash_truck', 'wall_bad',\n",
       "       'wall_reg', 'roof_bad', 'roof_reg', 'floor_bad', 'floor_reg',\n",
       "       'disabled_ppl', 'male', 'under10', 'free', 'married', 'separated',\n",
       "       'single', 'hh_head', 'hh_spouse', 'hh_child', 'num_65plus',\n",
       "       'dependency_rate', 'male_hh_head_educ', 'female_hh_head_educ',\n",
       "       'meaneduc', 'educ_primary_inc', 'educ_primary', 'educ_secondary_inc',\n",
       "       'educ_secondary', 'educ_undergrad', 'ppl_per_room', 'house_owned_full',\n",
       "       'house_owned_paying', 'house_rented', 'house_other', 'computer',\n",
       "       'television', 'num_mobilephones', 'region_central', 'region_Chorotega',\n",
       "       'region_pacifico', 'region_brunca', 'region_antlantica',\n",
       "       'region_huetar', 'urban_zone', 'age', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 11: Print info on data  ####\n",
    "\n",
    "costa_clean.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 12: Split into training and test sets  ####\n",
    "\n",
    "# Select the predictors and target.\n",
    "X = costa_clean.drop(['Target'], axis = 1)\n",
    "y = np.array(costa_clean['Target'])\n",
    "\n",
    "# Set the seed to 1.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Split into training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 13: Tuning random forest model  ####\n",
    "\n",
    "forest = pickle.load(open(\"model_forest.sav\",\"rb\"))\n",
    "forest.get_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 16: Parameter grid  ####\n",
    "\n",
    "# Number of trees in random forest.\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split.\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree.\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node.\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node.\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the random grid.\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "print(random_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 17: Set up cross-validation function  ####\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = forest, \n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 100,\n",
    "                               cv = 3, \n",
    "                               verbose = 0,\n",
    "                               random_state = 1, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model.\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 18: Optimized random forest model  ####\n",
    "\n",
    "optimized_forest = RandomForestClassifier(criterion = 'gini',\n",
    "                                          n_estimators = 1000,\n",
    "                                          min_samples_split = 5,\n",
    "                                          min_samples_leaf = 2,\n",
    "                                          max_features = 'sqrt',\n",
    "                                          max_depth = 10,\n",
    "                                          random_state = 1)\n",
    "optimized_forest.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 20: Exercise 1  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 22: Predict using the best model parameters  ####\n",
    "\n",
    "optimized_forest_y_predict = optimized_forest.predict(X_test)\n",
    "# Look at the first few predictions.\n",
    "print(optimized_forest_y_predict[0:5, ])\n",
    "optimized_forest_accuracy = metrics.accuracy_score(y_test, optimized_forest_y_predict)\n",
    "print (\"Accuracy on test data (best model): \", optimized_forest_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 23: Optimized random forest: save final accuracy  ####\n",
    "\n",
    "model_final_optimized = pickle.load(open(\"model_final_forest_gbm.sav\",\"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 24: Optimized random forest: save final accuracy  ####\n",
    "\n",
    "# Add the model to our dataframe.\n",
    "model_final_optimized = model_final_optimized.append({'metrics' : \"accuracy\" ,\n",
    "'values' : round(optimized_forest_accuracy, 4),\n",
    "'model':'optimized forest' } ,\n",
    "ignore_index = True)\n",
    "print(model_final_optimized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 26: Exercise 2  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 32: Define an optimal number function  ####\n",
    "\n",
    "# Define function that will determine the optimal number for each parameter.\n",
    "def optimal_parameter(values,test_results):\n",
    "    best_test_value = max(test_results)\n",
    "    best_test_index = test_results.index(best_test_value)\n",
    "    best_value = values[best_test_index]\n",
    "    return(best_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 33: Optimize: learning rate  ####\n",
    "\n",
    "# Learning Rate\n",
    "learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "\n",
    "for eta in learning_rates:\n",
    "    model = GradientBoostingClassifier(learning_rate=eta)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, train_pred)\n",
    "    train_results.append(acc_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    test_results.append(acc_test)\n",
    "\n",
    "optimal_learning_rate = optimal_parameter(learning_rates, test_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 34: Plot: learning rate  ####\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(learning_rates, train_results,'b', label= \"Train accuracy\")\n",
    "line2, = plt.plot(learning_rates, test_results, 'r', label= \"Test accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 35: Optimize: n estimators  ####\n",
    "\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for estimator in n_estimators:\n",
    "    model = GradientBoostingClassifier(n_estimators=estimator)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, train_pred)\n",
    "    train_results.append(acc_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    test_results.append(acc_test)\n",
    "\n",
    "optimal_n_estimators = optimal_parameter(n_estimators, test_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 36: Plot: n estimators  ####\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label= \"Train accuracy\")\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label= \"Test accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 37: Optimize: max depth  ####\n",
    "\n",
    "# Max depth:\n",
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    model = GradientBoostingClassifier(max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, train_pred)\n",
    "    train_results.append(acc_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    test_results.append(acc_test)\n",
    "\n",
    "# Store optimal max_depth.\n",
    "optimal_max_depth = optimal_parameter(max_depths, test_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 38: Plot: max depth  ####\n",
    "\n",
    "# Plot max depth over 1-32.\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label= \"Train accuracy\")\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label= \"Test accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 39: Optimize: min samples split  ####\n",
    "\n",
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint = True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for min_samples_split in min_samples_splits:\n",
    "    model = GradientBoostingClassifier(min_samples_split = min_samples_split)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, train_pred)\n",
    "    train_results.append(acc_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    test_results.append(acc_test)\n",
    "\n",
    "    # Store optimal min_samples_split.\n",
    "optimal_min_samples_split = optimal_parameter(min_samples_splits, test_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 40: Plot: min samples split  ####\n",
    "\n",
    "line1, = plt.plot(min_samples_splits, train_results, 'b', label = \"Train accuracy\")\n",
    "line2, = plt.plot(min_samples_splits, test_results, 'r', label = \"Test accuracy\")\n",
    "plt.legend(handler_map = {line1: HandlerLine2D(numpoints = 2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('min samples split')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 41: Optimize: min samples leaf  ####\n",
    "\n",
    "# Min_samples_leaf:\n",
    "min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint = True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "    model = GradientBoostingClassifier(min_samples_leaf = min_samples_leaf)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, train_pred)\n",
    "    train_results.append(acc_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    test_results.append(acc_test)\n",
    "\n",
    "\n",
    "optimal_min_samples_leafs = optimal_parameter(min_samples_leafs, test_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 42: Plot: min samples leaf  ####\n",
    "\n",
    "line1, = plt.plot(min_samples_leafs, train_results, 'b', label = \"Train accuracy\")\n",
    "line2, = plt.plot(min_samples_leafs, test_results, 'r', label = \"Test accuracy\")\n",
    "plt.legend(handler_map = {line1: HandlerLine2D(numpoints = 2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('min samples leafs')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 43: Optimize: max features  ####\n",
    "\n",
    "# Max_features:\n",
    "max_features = list(range(1,X.shape[1]))\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_feature in max_features:\n",
    "    model = GradientBoostingClassifier(max_features = max_feature)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, train_pred)\n",
    "    # Add acc score to previous train results.\n",
    "    train_results.append(acc_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    # Add acc score to previous test results.\n",
    "    test_results.append(acc_test)\n",
    "\n",
    "optimal_max_features = optimal_parameter(max_features, test_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 44: Plot: max features  ####\n",
    "\n",
    "line1, = plt.plot(max_features, train_results, 'b', label = \"Train accuracy\")\n",
    "line2, = plt.plot(max_features, test_results, 'r', label = \"Test accuracy\")\n",
    "plt.legend(handler_map = {line1: HandlerLine2D(numpoints = 2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('max features')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 45: Optimized model  ####\n",
    "\n",
    "print(\"The optimal learning rate is:\", optimal_learning_rate)\n",
    "print(\"The optimal number of estimators is:\", optimal_n_estimators)\n",
    "print(\"The optimal max depth is:\", optimal_max_depth)\n",
    "print(\"The optimal min samples split is:\", optimal_min_samples_split)\n",
    "print(\"The optimal min samples leaf is:\", optimal_min_samples_leafs)\n",
    "print(\"The optimal max features is:\", optimal_max_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 47: Exercise 3  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 49: Build optimized model  ####\n",
    "\n",
    "# Set the seed.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Implement the decision tree on X_train.\n",
    "gbm_optimized = GradientBoostingClassifier(learning_rate = optimal_learning_rate,\n",
    "n_estimators = optimal_n_estimators,\n",
    "max_depth = optimal_max_depth,\n",
    "min_samples_split = optimal_min_samples_split,\n",
    "min_samples_leaf = optimal_min_samples_leafs,\n",
    "max_features = optimal_max_features)\n",
    "\n",
    "# We can now see our optimized features where before they were just default:\n",
    "print(gbm_optimized)\n",
    "\n",
    "gbm_optimized_fit = gbm_optimized.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 50: Predict with optimized model  ####\n",
    "\n",
    "# Predict on X_test.\n",
    "y_predict_gbm_optimized = gbm_optimized.predict(X_test)\n",
    "\n",
    "# Accuracy score.\n",
    "acc_score_gbm_optimized = accuracy_score(y_test, y_predict_gbm_optimized)\n",
    "\n",
    "print(acc_score_gbm_optimized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 51: Add accuracy score to the final scores  ####\n",
    "\n",
    "model_final_optimized = model_final_optimized.append({'metrics' : \"accuracy\" ,\n",
    "'values' : round(acc_score_gbm_optimized,4),\n",
    "'model':'gbm_optimized'} ,\n",
    "ignore_index = True)\n",
    "print(model_final_optimized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 53: Final scores  ####\n",
    "\n",
    "print(model_final_optimized)\n",
    "pickle.dump(model_final_optimized, open(\"model_final_optimized_ensemble.sav\", \"wb\" ))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
