{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## 13 ADVANCED CLASSIFICATION DAY4 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 2: Directory settings  ####\n",
    "\n",
    "# Set `main_dir` to the location of your `af-werx` folder (for Linux).\n",
    "main_dir = \"/home/[username]/Desktop/af-werx\"\n",
    "# Set `main_dir` to the location of your `af-werx` folder (for Mac).\n",
    "main_dir = '/Users/[username]/Desktop/af-werx'\n",
    "# Set `main_dir` to the location of your `af-werx` folder (for Windows).\n",
    "main_dir = \"C:\\\\Users\\\\[username]\\\\Desktop\\\\af-werx\"\n",
    "# Make `data_dir` from the `main_dir` and\n",
    "# remainder of the path to data directory.\n",
    "data_dir = main_dir + \"/data\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 3: Loading packages  ####\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import datetime as dt\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for safety capture the original main path - when you re-run the book we will always start from the original folder\n",
    "# this is similar to here() in R which captures the project root.\n",
    "# https://github.com/ipython/ipython/issues/10123\n",
    "nb_root = globals()['_dh']\n",
    "os.chdir(nb_root[0])\n",
    " \n",
    "main_dir = os.path.abspath(os.path.join (\"..\",))\n",
    "\n",
    "# Make `data_dir` and 'path_dir' from the `main_dir` and\n",
    "data_dir = os.path.join(main_dir, \"data\")\n",
    "plot_dir = os.path.join(main_dir, \"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/datasociety/Desktop/af-werx/Data Science - Course Guides/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-65301ae8fc76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Set working directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Check working directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/datasociety/Desktop/af-werx/Data Science - Course Guides/data'"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 4: Working directory  ####\n",
    "\n",
    "# Set working directory.\n",
    "os.chdir(data_dir)\n",
    "# Check working directory.\n",
    "print(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 10: Load the dataset  ####\n",
    "\n",
    "costa_rica = pd.read_csv(\"costa_rica_poverty.csv\")\n",
    "costa_rica.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 11: Subset the data for baseline model  ####\n",
    "\n",
    "costa_subset = costa_rica[['rooms', 'males_tot', 'females_tot', 'years_of_schooling', 'num_child', 'num_adults', 'num_65plus',\n",
    "'dependency_rate', 'male_hh_head_educ', 'female_hh_head_educ', 'meaneduc',\n",
    "'bedrooms', 'ppl_per_room', 'num_mobilephones', 'age', 'Target']]\n",
    "costa_subset.shape\n",
    "costa_subset.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 12: Create target and predictors  ####\n",
    "\n",
    "costa_subset['Target_binary'] = np.where(costa_subset['Target'] <= 3, 'vulnerable', 'non_vulnerable')\n",
    "\n",
    "X = costa_subset.drop(['Target', 'Target_binary'], axis = 1)\n",
    "y = costa_subset.Target_binary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 13: Logistic regression function  ####\n",
    "\n",
    "def logistic_model(X,y):\n",
    "    np.random.seed(1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    return(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 14: Create the baseline and save the result  ####\n",
    "\n",
    "accuracy1 = logistic_model(X,y)\n",
    "accuracy1\n",
    "performance_df = pd.DataFrame(columns = ['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "\n",
    "s = pd.Series(['Costa_rica', 'baseline_model', 'accuracy', accuracy1], index = ['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 20: Exercise 1  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 22: Imputation using regression  ####\n",
    "\n",
    "# Subset the data once again.\n",
    "costa_regression_subset = costa_rica[['rooms','males_tot', 'females_tot', 'years_of_schooling', 'num_child', 'num_adults', 'num_65plus',\n",
    "'dependency_rate', 'male_hh_head_educ', 'female_hh_head_educ', 'meaneduc',\n",
    "'bedrooms', 'ppl_per_room', 'num_mobilephones', 'age', 'monthly_rent', 'Target']]\n",
    "\n",
    "# Create target variable.\n",
    "costa_regression_subset['Target_binary'] = np.where(costa_regression_subset['Target'] <= 3, 'vulnerable', 'non_vulnerable')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 23: Imputation using regression  ####\n",
    "\n",
    "train_subset = costa_regression_subset[~costa_regression_subset['monthly_rent'].isna()]\n",
    "test_subset = costa_regression_subset[costa_regression_subset['monthly_rent'].isna()]\n",
    "\n",
    "print(train_subset.shape)\n",
    "print(test_subset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 24: Imputation using regression  ####\n",
    "\n",
    "X_reg_train = train_subset.drop(['Target', 'Target_binary', 'monthly_rent'], axis = 1)\n",
    "y_reg_train = train_subset.monthly_rent\n",
    "X_reg_test = test_subset.drop(['Target', 'Target_binary', 'monthly_rent'], axis = 1)\n",
    "\n",
    "X_reg_train.shape\n",
    "# Fit the model and predict on test\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_reg_train, y_reg_train)\n",
    "y_pred = linear_model.predict(X_reg_test)\n",
    "len(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 25: Imputation using regression  ####\n",
    "\n",
    "# Impute the monthly rent with predicted target value.\n",
    "test_subset['monthly_rent'] = y_pred\n",
    "\n",
    "# Concatenate training and test data.\n",
    "imputed_df = pd.concat([train_subset, test_subset])\n",
    "\n",
    "# Split X and y to predict our poverty level now.\n",
    "imputed_X = imputed_df.drop(['Target', 'Target_binary'], axis = 1)\n",
    "imputed_y = imputed_df.Target_binary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 26: Model performance after imputation  ####\n",
    "\n",
    "accuracy2 = logistic_model(imputed_X,imputed_y)\n",
    "print(accuracy2)\n",
    "s = pd.Series(['Costa_rica', 'na_imputation_regression', 'accuracy', accuracy2], index = ['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 29: NA imputation with median  ####\n",
    "\n",
    "costa_rica['monthly_rent'].isnull().value_counts()\n",
    "costa_rica['monthly_rent'].fillna(costa_rica['monthly_rent'].median(), inplace = True)\n",
    "X = pd.concat([X, costa_rica['monthly_rent']], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 30: Model on NA imputed data  ####\n",
    "\n",
    "accuracy3 = logistic_model(X,y)\n",
    "accuracy3\n",
    "s = pd.Series(['Costa_rica', 'na_imputation_median', 'accuracy', accuracy3], index=['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 33: Binning a variable in our data  ####\n",
    "\n",
    "# Bin the variables.\n",
    "X['school_category'] = pd.cut(X.age, [-1,10,25], labels = [\"less_than_10\", \"more_than_10\"])\n",
    "\n",
    "# Add the school category as one of the variables.\n",
    "X['school_category'] = X['school_category'].cat.codes\n",
    "school_cat = pd.get_dummies(X['school_category'], prefix = 'school', drop_first = True)\n",
    "X = pd.concat([X, school_cat], axis = 1)\n",
    "\n",
    "# Drop the monthly rent and years of schooling variables.\n",
    "X.drop(['years_of_schooling', 'monthly_rent', 'school_category'], axis = 1, inplace = True)\n",
    "X.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 34: Model performance after binning  ####\n",
    "\n",
    "accuracy4 = logistic_model(X,y)\n",
    "print(accuracy4)\n",
    "s = pd.Series(['Costa_rica', 'binning', 'accuracy', accuracy4], index=['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 36: Exercise 2  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 40: Additional features for model 1  ####\n",
    "\n",
    "cat_count_subset = costa_rica[['household_id', 'married', 'separated', 'single']]\n",
    "cat_count_subset.head()\n",
    "count_grouped = cat_count_subset.groupby(['household_id']).sum()\n",
    "count_grouped.reset_index(inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 41: View the additional features  ####\n",
    "\n",
    "count_grouped.head()\n",
    "# Add the features to our model subset.\n",
    "X = pd.concat([X, costa_rica['household_id']], axis = 1)          #<- add household id to X to find the match\n",
    "X = pd.merge(X, count_grouped, how = 'left', on = 'household_id') #<- merge on household id\n",
    "X.drop(['household_id'], axis = 1, inplace = True)                #<- drop household id\n",
    "X.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 42: Additional feature model 1  ####\n",
    "\n",
    "accuracy5 = logistic_model(X, y)\n",
    "print(accuracy5)\n",
    "s = pd.Series(['Costa_rica', 'categorical_summary', 'accuracy', accuracy5], index=['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 43: Additional features for model 2  ####\n",
    "\n",
    "numerical_summary_subset = costa_rica[['household_id', 'years_of_schooling', 'age']]\n",
    "\n",
    "numerical_summary_subset = numerical_summary_subset.groupby(['household_id']).agg(['min', 'max', 'mean', 'sum'])\n",
    "\n",
    "numerical_summary_subset.columns = ['school_min', 'school_max', 'school_mean', 'school_sum',\n",
    "'age_min', 'age_max', 'age_mean', 'age_sum']\n",
    "\n",
    "numerical_summary_subset.reset_index(inplace = True)\n",
    "\n",
    "numerical_summary_subset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 44: Add the additional features  ####\n",
    "\n",
    "X = pd.concat([X, costa_rica['household_id']], axis = 1)\n",
    "X = pd.merge(X, numerical_summary_subset, how = 'left', on = 'household_id')\n",
    "X.drop(['household_id', 'married', 'separated', 'single'], axis = 1, inplace = True) #<- drop previous features\n",
    "X.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 45: Additional feature model 2  ####\n",
    "\n",
    "accuracy6 = logistic_model(X,y)\n",
    "print(accuracy6)\n",
    "s = pd.Series(['Costa_rica', 'numerical_summary', 'accuracy', accuracy6], index=['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 46: Additional feature model 3  ####\n",
    "\n",
    "costa_rica['male_per_room'] = costa_rica['males_tot'] / costa_rica['rooms']\n",
    "costa_rica['female_per_room'] = costa_rica['females_tot'] / costa_rica['rooms']\n",
    "costa_rica['room_per_person'] = costa_rica['rooms'] / costa_rica['ppl_total']\n",
    "costa_rica['bed_per_room'] = costa_rica['bedrooms'] / costa_rica['rooms']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 48: Additional feature model 3  ####\n",
    "\n",
    "costa_rica['wall'] = np.argmax(np.array(costa_rica[['wall_bad', 'wall_reg', 'wall_good']]), axis = 1)\n",
    "costa_rica['roof'] = np.argmax(np.array(costa_rica[['roof_bad', 'roof_reg', 'roof_good']]), axis = 1)\n",
    "costa_rica['floor'] = np.argmax(np.array(costa_rica[['floor_bad', 'floor_reg', 'floor_good']]), axis = 1)\n",
    "costa_rica['house_condition'] = costa_rica['wall'] + costa_rica['roof'] + costa_rica['floor']\n",
    "costa_rica[['wall', 'roof', 'floor', 'house_condition']].head()\n",
    "X = pd.concat([X, costa_rica['house_condition'], costa_rica['male_per_room'], costa_rica['female_per_room'],\n",
    "costa_rica['room_per_person'], costa_rica['bed_per_room']], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 49: Additional feature model 3  ####\n",
    "\n",
    "accuracy7 = logistic_model(X,y)\n",
    "print(accuracy7)\n",
    "s = pd.Series(['Costa_rica', 'additional_features', 'accuracy', accuracy7], index=['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 52: Feature engineering in Costa Rica data  ####\n",
    "\n",
    "dummy_columns = ['urban_zone', 'rural_zone', 'tablet', 'house_rented', 'computer', 'television']\n",
    "\n",
    "for i in range(0, len(dummy_columns)):\n",
    "    colname = \"df_\" + str(i)\n",
    "    costa_rica[dummy_columns[i]] = pd.Categorical(costa_rica[dummy_columns[i]])\n",
    "    costa_rica[dummy_columns[i]] = costa_rica[dummy_columns[i]].cat.codes\n",
    "    colname = pd.get_dummies(costa_rica[dummy_columns[i]], prefix = (str(dummy_columns[i])), drop_first = True)\n",
    "    X = pd.concat([X, colname], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 53: View the features  ####\n",
    "\n",
    "X = X.drop(['house_condition', 'male_per_room', 'female_per_room', 'room_per_person', 'bed_per_room'], axis = 1)\n",
    "\n",
    "X.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 54: Model after adding dummy variables  ####\n",
    "\n",
    "accuracy8 = logistic_model(X, y)\n",
    "print(accuracy8)\n",
    "s = pd.Series(['Costa_rica', 'dummy_encoding', 'accuracy', accuracy8], index = ['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 57: Exercise 3  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 60: Data set for date features  ####\n",
    "\n",
    "occupancy_data = pd.read_csv('occupancy_data.csv')\n",
    "occupancy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 61: Data set for date features  ####\n",
    "\n",
    "occupancy_data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 62: Baseline model for comparison  ####\n",
    "\n",
    "occupancy_X = occupancy_data.drop(['date', 'Occupancy'], axis = 1)\n",
    "occupancy_y = occupancy_data.Occupancy\n",
    "\n",
    "accuracy9 = logistic_model(occupancy_X, occupancy_y)\n",
    "print(accuracy9)\n",
    "s = pd.Series(['Occupancy', 'occupancy_baseline', 'accuracy', accuracy9], index = ['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 63: Extract date features   ####\n",
    "\n",
    "occupancy_data['date'] = pd.to_datetime(occupancy_data['date'], format = '%d/%m/%y %H:%M')\n",
    "occupancy_data['day'] = occupancy_data['date'].dt.day\n",
    "occupancy_data['month'] = occupancy_data['date'].dt.month\n",
    "occupancy_data['year'] = occupancy_data['date'].dt.year\n",
    "occupancy_data['hour'] = occupancy_data['date'].dt.hour\n",
    "occupancy_data['minute'] = occupancy_data['date'].dt.minute\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 64: Frequency table of date features  ####\n",
    "\n",
    "occupancy_data.year.value_counts()\n",
    "occupancy_data.month.value_counts()\n",
    "occupancy_data.day.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 65: Add date features to model data  ####\n",
    "\n",
    "dummy_columns = ['hour', 'month']\n",
    "\n",
    "for i in range(0, len(dummy_columns)):\n",
    "    colname = \"df_\" + str(i)\n",
    "    occupancy_data[dummy_columns[i]] = pd.Categorical(occupancy_data[dummy_columns[i]])\n",
    "    occupancy_data[dummy_columns[i]] = occupancy_data[dummy_columns[i]].cat.codes\n",
    "    colname = pd.get_dummies(occupancy_data[dummy_columns[i]], prefix = (str(dummy_columns[i])), drop_first = True)\n",
    "    occupancy_data = pd.concat([occupancy_data, colname], axis = 1)\n",
    "    occupancy_X = occupancy_data.drop(['date', 'minute', 'day', 'year', 'hour', 'month'], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 66: View the training data  ####\n",
    "\n",
    "occupancy_X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 67: Model the data and find accuracy  ####\n",
    "\n",
    "accuracy10 = logistic_model(occupancy_X, occupancy_y)\n",
    "print(accuracy10)\n",
    "s = pd.Series(['Occupancy', 'with_date_features', 'accuracy', accuracy10], index = ['dataset_name', 'model_name', 'model_metric', 'metric_value'])\n",
    "performance_df = performance_df.append(s, ignore_index = True)\n",
    "performance_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
