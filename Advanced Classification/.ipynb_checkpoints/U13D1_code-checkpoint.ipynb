{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## 13 ADVANCED CLASSIFICATION DAY1 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 2: Directory settings  ####\n",
    "\n",
    "# Set `main_dir` to the location of your `af-werx` folder (for Linux).\n",
    "main_dir = \"/home/[username]/Desktop/af-werx\"\n",
    "# Set `main_dir` to the location of your `af-werx` folder (for Mac).\n",
    "main_dir = '/Users/[username]/Desktop/af-werx'\n",
    "# Set `main_dir` to the location of your `af-werx` folder (for Windows).\n",
    "main_dir = \"C:\\\\Users\\\\[username]\\\\Desktop\\\\af-werx\"\n",
    "# Make `data_dir` from the `main_dir` and\n",
    "# remainder of the path to data directory.\n",
    "data_dir = main_dir + \"/data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `main_dir` to the location of your `af-werx` folder (for Mac).\n",
    "main_dir = '/Users/kiru/Desktop/af-werx'\n",
    "data_dir = main_dir + \"/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 3: Loading packages  ####\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textwrap import wrap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# New today - random forest and boosting packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib.legend_handler import HandlerLine2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<on my machine>>\n",
    "# I would like to use relative paths but the class has been using absoulute paths so lets not change too much now\n",
    "data_dir = '/Users/user/Dropbox/Teaching_folders/_Current teaching/data_society_data_science/data'\n",
    "# <<on my machine>>\n",
    "# I would like to use relative paths but the class has been using absoulute paths so lets not change too much now\n",
    "plot_dir = '/Users/user/Dropbox/Teaching_folders/_Current teaching/data_society_data_science/plots'\n",
    "\n",
    "os.chdir(data_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 4: Working directory  ####\n",
    "\n",
    "# Set working directory.\n",
    "os.chdir(data_dir)\n",
    "# Check working directory.\n",
    "print(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 27: Load the cleaned dataset  ####\n",
    "\n",
    "os.chdir(data_dir)\n",
    "costa_clean = pickle.load(open(\"costa_no_hc.sav\",\"rb\"))\n",
    "print(costa_clean.head())\n",
    "\n",
    "\n",
    "#– RemovehouseholdIDandindividualID \n",
    "#– Removevariableswithover50%NAs\n",
    "#– Transformtargetvariabletobinary\n",
    "#– Removehighlycorrelatedvariables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 28: Print info on data  ####\n",
    "\n",
    "costa_clean.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 29: Split into training and test sets  ####\n",
    "\n",
    "# Select the predictors and target.\n",
    "X = costa_clean.drop(['Target'], axis = 1)\n",
    "y = np.array(costa_clean['Target'])\n",
    "\n",
    "# Set the seed to 1.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Split into the training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 31: Building our model  ####\n",
    "\n",
    "forest = RandomForestClassifier(criterion = 'gini', n_estimators = 100,\n",
    "random_state = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 32: Fitting our model  ####\n",
    "\n",
    "# Fit the saved model to your training data.\n",
    "forest.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 33: Predicting with our data  ####\n",
    "\n",
    "# Predict on test data.\n",
    "y_predict_forest = forest.predict(X_test)\n",
    "\n",
    "# Look at the first few predictions.\n",
    "print(y_predict_forest[0:5,])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 34: Confusion matrix and accuracy  ####\n",
    "\n",
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_forest = metrics.confusion_matrix(y_test, y_predict_forest)\n",
    "print(conf_matrix_forest)\n",
    "accuracy_forest = metrics.accuracy_score(y_test, y_predict_forest)\n",
    "print(\"Accuracy for random forest on test data: \", accuracy_forest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 35: Accuracy of the training dataset  ####\n",
    "\n",
    "# Compute accuracy using training data.\n",
    "acc_train_forest = forest.score(X_train, y_train)\n",
    "\n",
    "print (\"Train Accuracy:\", acc_train_forest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 36: Save final accuracy  ####\n",
    "\n",
    "model_final_forest_gbm = pickle.load(open(\"model_final_tree_all.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 37: Save final accuracy  ####\n",
    "\n",
    "# Add the model to our dataframe.\n",
    "model_final_forest_gbm = model_final_forest_gbm.append({'metrics' : \"accuracy\" ,\n",
    "'values' : round(accuracy_forest,4),\n",
    "'model':'random forest' } ,\n",
    "ignore_index = True)\n",
    "print(model_final_forest_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 40: Subsetting our features  ####\n",
    "\n",
    "costarica_features = costa_clean.drop('Target', axis = 1)\n",
    "features = costarica_features.columns\n",
    "importances = forest.feature_importances_\n",
    "indices = np. argsort(importances)[::-1]\n",
    "top_indices = indices[0:10][::-1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(top_indices)), importances[top_indices], color = 'b', align = 'center')\n",
    "labels = features[top_indices]\n",
    "labels = [ '\\n'.join(wrap(l,13)) for l in labels ]\n",
    "plt.yticks(range(len(top_indices)), labels)\n",
    "plt.xlabel('Relative Importance')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 42: Save the random forest model  ####\n",
    "\n",
    "pickle.dump(forest, open(\"model_forest.sav\",\"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 44: Exercise 1  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 56: Boosting: build model  ####\n",
    "\n",
    "# Save the parameters we will be using for our gradient boosting classifier.\n",
    "gbm = GradientBoostingClassifier(n_estimators = 200,\n",
    "learning_rate = 1,\n",
    "max_depth = 2,\n",
    "random_state = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 57: Boosting: fit model  ####\n",
    "\n",
    "# Fit the saved model to your training data.\n",
    "gbm.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 58: Boosting: predict  ####\n",
    "\n",
    "# Predict on test data.\n",
    "predicted_values_gbm = gbm.predict(X_test)\n",
    "print(predicted_values_gbm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 59: Confusion matrix and accuracy  ####\n",
    "\n",
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_boosting = metrics.confusion_matrix(y_test, predicted_values_gbm)\n",
    "print(conf_matrix_boosting)\n",
    "# Compute test model accuracy score.\n",
    "accuracy_gbm = metrics.accuracy_score(y_test, predicted_values_gbm)\n",
    "print('Accuracy of gbm on test data: ', accuracy_gbm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 60: Accuracy of training model  ####\n",
    "\n",
    "# Compute accuracy using training data.\n",
    "train_accuracy_gbm = gbm.score(X_train, y_train)\n",
    "\n",
    "print (\"Train Accuracy:\", train_accuracy_gbm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 61: Pickle final accuracy  ####\n",
    "\n",
    "# Add the model to our dataframe.\n",
    "model_final_forest_gbm = model_final_forest_gbm.append({'metrics' : \"accuracy\" ,\n",
    "'values' : round(accuracy_gbm,4),\n",
    "'model': 'boosting' } ,\n",
    "ignore_index = True)\n",
    "print(model_final_forest_gbm)\n",
    "pickle.dump(model_final_forest_gbm, open(\"model_final_forest_gbm.sav\", \"wb\" ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 62: Our top 10 features  ####\n",
    "\n",
    "features = costarica_features.columns\n",
    "importances = gbm.feature_importances_\n",
    "indices = np. argsort(importances)[::-1]\n",
    "top_indices = indices[0:10][::-1]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(top_indices)), importances[top_indices], color = 'b', align = 'center')\n",
    "labels = features[top_indices]\n",
    "labels = [ '\\n'.join(wrap(l,13)) for l in labels ]\n",
    "plt.yticks(range(len(top_indices)), features[top_indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
